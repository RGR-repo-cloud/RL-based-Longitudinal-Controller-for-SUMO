{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functionality for calculating training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MAX_STEP = 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(paths, file_name):\n",
    "    files = []\n",
    "    for p in paths:\n",
    "        files.append(p + file_name)\n",
    "\n",
    "    datas = []\n",
    "    avg_eps_lengths = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        data = []\n",
    "        num_epidodes = 0\n",
    "        num_steps = 0\n",
    "        first_episode = 0\n",
    "        first_step = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if index == 0:\n",
    "                first_episode = row['episode']\n",
    "                first_step = row['step']\n",
    "            data.append(row['episode_reward'])\n",
    "            if row['step'] >= MAX_STEP:\n",
    "                num_epidodes = row['episode']\n",
    "                num_steps = row['step']\n",
    "                break\n",
    "        avg_eps_length = (num_steps - first_step) / (num_epidodes - first_episode)\n",
    "        avg_eps_lengths.append(avg_eps_length)\n",
    "        datas.append(data)\n",
    "\n",
    "\n",
    "    # calculate metrics\n",
    "\n",
    "    maxs = []\n",
    "    avgs = []\n",
    "    stds = []\n",
    "    for data in datas:\n",
    "        maxs.append(max(data))\n",
    "        avgs.append(np.mean(data))\n",
    "        stds.append(np.std(data))\n",
    "\n",
    "    print(\"avg_max\")\n",
    "    print(np.mean(maxs))\n",
    "    print(\"avg_mean\")\n",
    "    print(np.mean(avgs))\n",
    "    print(\"avg_std\")\n",
    "    print(np.mean(stds))\n",
    "    print(\"avg_eps_length\")\n",
    "    print(np.mean(avg_eps_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation of single training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_max\n",
      "-15.190607837194484\n",
      "avg_mean\n",
      "-16.199425929202743\n",
      "avg_std\n",
      "0.8305122320823956\n",
      "avg_eps_length\n",
      "506.4513618677043\n"
     ]
    }
   ],
   "source": [
    "path = '../exp/path_to_training-run/'\n",
    "\n",
    "file_name = 'combined_eval_data.csv'\n",
    "\n",
    "calc_metrics([path], file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation of multiple training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_max\n",
      "-15.00167816320405\n",
      "avg_mean\n",
      "-17.265800805297566\n",
      "avg_std\n",
      "2.5125151506113683\n",
      "avg_eps_length\n",
      "584.951516474747\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "'../exp/path_to_training-run1/',\n",
    "'../exp/path_to_training-run2/',\n",
    "'../exp/path_to_training-run3/',\n",
    "'../exp/path_to_training-run4/'\n",
    "]\n",
    "\n",
    "\n",
    "file_name = 'combined_eval_data.csv'\n",
    "\n",
    "calc_metrics(paths, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

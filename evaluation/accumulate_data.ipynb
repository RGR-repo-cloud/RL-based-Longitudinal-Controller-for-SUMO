{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../exp/2024-01-31/17-07/'\n",
    "\n",
    "csv_train_file_name = 'combined_train_data.csv'\n",
    "csv_eval_file_name = 'combined_eval_data.csv'\n",
    "\n",
    "agent_ids = ['follower0_0', 'follower1_0', 'follower2_0', 'follower3_0', 'follower4_0']\n",
    "summable_train_keys = ['actor_entropy', 'actor_loss', 'actor_target_entropy', 'alpha_loss', 'alpha_value', 'batch_reward', 'critic_loss', 'duration', 'episode_reward']\n",
    "static_train_keys = ['episode', 'step']\n",
    "summable_eval_keys = ['episode_reward']\n",
    "static_eval_keys = ['episode', 'step']\n",
    "\n",
    "train_file_names = []\n",
    "eval_file_names = []\n",
    "for id in agent_ids:\n",
    "    train_file_names.append(path + \"train_\" + id + \".csv\")\n",
    "    eval_file_names.append(path + \"eval_\" + id + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_dict = {}\n",
    "for file_index, file in enumerate(train_file_names):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    if file_index == 0:\n",
    "        for sum_key in summable_train_keys:\n",
    "            train_data_dict[sum_key] = []\n",
    "        for static_key in static_train_keys:\n",
    "            train_data_dict[static_key] = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for sum_key in summable_train_keys:\n",
    "            if file_index == 0:\n",
    "                train_data_dict[sum_key].append(row[sum_key])\n",
    "            else:\n",
    "                train_data_dict[sum_key][index] += row[sum_key]\n",
    "        if file_index == 0:\n",
    "            for static_key in static_train_keys:\n",
    "                train_data_dict[static_key].append(row[static_key])\n",
    "\n",
    "\n",
    "eval_data_dict = {}\n",
    "for file_index, file in enumerate(eval_file_names):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    if file_index == 0:\n",
    "        for sum_key in summable_eval_keys:\n",
    "            eval_data_dict[sum_key] = []\n",
    "        for static_key in static_eval_keys:\n",
    "            eval_data_dict[static_key] = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for sum_key in summable_eval_keys:\n",
    "            if file_index == 0:\n",
    "                eval_data_dict[sum_key].append(row[sum_key])\n",
    "            else:\n",
    "                eval_data_dict[sum_key][index] += row[sum_key]\n",
    "        if file_index == 0:\n",
    "            for static_key in static_eval_keys:\n",
    "                eval_data_dict[static_key].append(row[static_key])\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train_data_dict)\n",
    "eval_df = pd.DataFrame.from_dict(eval_data_dict)\n",
    "\n",
    "train_df.to_csv(path + csv_train_file_name)\n",
    "eval_df.to_csv(path + csv_eval_file_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
